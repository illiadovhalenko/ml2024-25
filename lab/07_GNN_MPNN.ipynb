{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "#### Google Colab compatible version\n",
    "The following setup is suitable for Google Colab with T4 GPU.\n",
    "\n",
    "To enable T4 GPU: Connect configuration menu $\\rightarrow$ Change runtime type $\\rightarrow$ Hardware accelerator: T4 GPU"
   ],
   "metadata": {
    "id": "Ho7QzWvk8IcB"
   },
   "id": "Ho7QzWvk8IcB"
  },
  {
   "cell_type": "code",
   "source": [
    "!git clone https://github.com/gmum/ml2024-25.git"
   ],
   "metadata": {
    "id": "RWInpnEv7_d9",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "d692d8bb-6c40-4727-e40e-8e4543fe0754"
   },
   "id": "RWInpnEv7_d9",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cloning into 'ml2024-25'...\n",
      "remote: Enumerating objects: 151, done.\u001B[K\n",
      "remote: Counting objects: 100% (35/35), done.\u001B[K\n",
      "remote: Compressing objects: 100% (18/18), done.\u001B[K\n",
      "remote: Total 151 (delta 24), reused 20 (delta 17), pack-reused 116 (from 1)\u001B[K\n",
      "Receiving objects: 100% (151/151), 37.37 MiB | 11.29 MiB/s, done.\n",
      "Resolving deltas: 100% (64/64), done.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "import sys\n",
    "sys.path.append('/content/ml2024-25/lab')  # This ensures import lab.checker later"
   ],
   "metadata": {
    "id": "zAjf4bUx42z8"
   },
   "id": "zAjf4bUx42z8",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e670bf640f110540",
    "outputId": "f5021df3-ab5d-4d9c-e371-6002fe86b13f"
   },
   "cell_type": "code",
   "source": [
    "!pip install torch==2.4.0 torchvision==0.19.0 torchaudio==2.4.0 --index-url https://download.pytorch.org/whl/cu121"
   ],
   "id": "e670bf640f110540",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
      "Collecting torch==2.4.0\n",
      "  Downloading https://download.pytorch.org/whl/cu121/torch-2.4.0%2Bcu121-cp310-cp310-linux_x86_64.whl (799.1 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m799.1/799.1 MB\u001B[0m \u001B[31m733.5 kB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting torchvision==0.19.0\n",
      "  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.19.0%2Bcu121-cp310-cp310-linux_x86_64.whl (7.1 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m7.1/7.1 MB\u001B[0m \u001B[31m63.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting torchaudio==2.4.0\n",
      "  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.4.0%2Bcu121-cp310-cp310-linux_x86_64.whl (3.4 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.4/3.4 MB\u001B[0m \u001B[31m57.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (1.13.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (2024.10.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.4.0)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m23.7/23.7 MB\u001B[0m \u001B[31m43.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.4.0)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m823.6/823.6 kB\u001B[0m \u001B[31m39.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.4.0)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m14.1/14.1 MB\u001B[0m \u001B[31m54.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.4.0)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m664.8/664.8 MB\u001B[0m \u001B[31m2.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.4.0)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m410.6/410.6 MB\u001B[0m \u001B[31m3.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.4.0)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m121.6/121.6 MB\u001B[0m \u001B[31m8.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch==2.4.0)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m56.5/56.5 MB\u001B[0m \u001B[31m15.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.4.0)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m124.2/124.2 MB\u001B[0m \u001B[31m8.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.4.0)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m196.0/196.0 MB\u001B[0m \u001B[31m6.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting nvidia-nccl-cu12==2.20.5 (from torch==2.4.0)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m176.2/176.2 MB\u001B[0m \u001B[31m6.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch==2.4.0)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m99.1/99.1 kB\u001B[0m \u001B[31m7.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting triton==3.0.0 (from torch==2.4.0)\n",
      "  Downloading https://download.pytorch.org/whl/triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m209.4/209.4 MB\u001B[0m \u001B[31m6.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.19.0) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.19.0) (11.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.0) (12.6.85)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.4.0) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.4.0) (1.3.0)\n",
      "Installing collected packages: triton, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torchvision, torchaudio\n",
      "  Attempting uninstall: nvidia-nccl-cu12\n",
      "    Found existing installation: nvidia-nccl-cu12 2.24.3\n",
      "    Uninstalling nvidia-nccl-cu12-2.24.3:\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.24.3\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
      "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
      "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n",
      "    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
      "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.6.0.74\n",
      "    Uninstalling nvidia-cudnn-cu12-9.6.0.74:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.6.0.74\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.5.1+cu121\n",
      "    Uninstalling torch-2.5.1+cu121:\n",
      "      Successfully uninstalled torch-2.5.1+cu121\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.20.1+cu121\n",
      "    Uninstalling torchvision-0.20.1+cu121:\n",
      "      Successfully uninstalled torchvision-0.20.1+cu121\n",
      "  Attempting uninstall: torchaudio\n",
      "    Found existing installation: torchaudio 2.5.1+cu121\n",
      "    Uninstalling torchaudio-2.5.1+cu121:\n",
      "      Successfully uninstalled torchaudio-2.5.1+cu121\n",
      "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvtx-cu12-12.1.105 torch-2.4.0+cu121 torchaudio-2.4.0+cu121 torchvision-0.19.0+cu121 triton-3.0.0\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install  dgl -f https://data.dgl.ai/wheels/torch-2.4/cu121/repo.html"
   ],
   "metadata": {
    "id": "aQPY-MIt8VaW",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "56bf9bed-d9b7-42d2-b42f-0107946aa9ec"
   },
   "id": "aQPY-MIt8VaW",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Looking in links: https://data.dgl.ai/wheels/torch-2.4/cu121/repo.html\n",
      "Collecting dgl\n",
      "  Downloading https://data.dgl.ai/wheels/torch-2.4/cu121/dgl-2.4.0%2Bcu121-cp310-cp310-manylinux1_x86_64.whl (355.2 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m355.2/355.2 MB\u001B[0m \u001B[31m3.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgl) (3.4.2)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.26.4)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from dgl) (24.2)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from dgl) (2.2.2)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (5.9.5)\n",
      "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (2.10.4)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from dgl) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.13.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgl) (4.67.1)\n",
      "Requirement already satisfied: torch<=2.4.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (2.4.0+cu121)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->dgl) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->dgl) (2.27.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->dgl) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2024.12.14)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (3.16.1)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (1.13.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (2024.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<=2.4.0->dgl) (12.6.85)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->dgl) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->dgl) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->dgl) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->dgl) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<=2.4.0->dgl) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<=2.4.0->dgl) (1.3.0)\n",
      "Installing collected packages: dgl\n",
      "Successfully installed dgl-2.4.0+cu121\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install dgllife"
   ],
   "metadata": {
    "id": "Yoyd-1nt8XVQ",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "1fc81fb8-4b30-4881-fbea-7128bdcd236f"
   },
   "id": "Yoyd-1nt8XVQ",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting dgllife\n",
      "  Downloading dgllife-0.3.2-py3-none-any.whl.metadata (667 bytes)\n",
      "Requirement already satisfied: scikit-learn>=0.22.2 in /usr/local/lib/python3.10/dist-packages (from dgllife) (1.6.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from dgllife) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.10/dist-packages (from dgllife) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgllife) (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from dgllife) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgllife) (1.13.1)\n",
      "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgllife) (3.4.2)\n",
      "Requirement already satisfied: hyperopt in /usr/local/lib/python3.10/dist-packages (from dgllife) (0.2.7)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from dgllife) (1.4.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->dgllife) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->dgllife) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->dgllife) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->dgllife) (2024.12.14)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.2->dgllife) (3.5.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from hyperopt->dgllife) (1.17.0)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from hyperopt->dgllife) (1.0.0)\n",
      "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from hyperopt->dgllife) (3.1.0)\n",
      "Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (from hyperopt->dgllife) (0.10.9.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->dgllife) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->dgllife) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->dgllife) (2024.2)\n",
      "Downloading dgllife-0.3.2-py3-none-any.whl (226 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m226.1/226.1 kB\u001B[0m \u001B[31m5.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hInstalling collected packages: dgllife\n",
      "Successfully installed dgllife-0.3.2\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install torch_geometric\n",
    "!pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.4.0+cu121.html  # Optional dependencies"
   ],
   "metadata": {
    "id": "kx1Y0mtj8ZRA",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "fab4539b-2ae8-4631-b6f7-63e2936703ab"
   },
   "id": "kx1Y0mtj8ZRA",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting torch_geometric\n",
      "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
      "\u001B[?25l     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/63.1 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m63.1/63.1 kB\u001B[0m \u001B[31m2.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.11.11)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2024.10.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.5)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.26.4)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
      "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.2.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.67.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.18.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2024.12.14)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->torch_geometric) (4.12.2)\n",
      "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.1/1.1 MB\u001B[0m \u001B[31m22.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hInstalling collected packages: torch_geometric\n",
      "Successfully installed torch_geometric-2.6.1\n",
      "Looking in links: https://data.pyg.org/whl/torch-2.4.0+cu121.html\n",
      "Collecting pyg_lib\n",
      "  Downloading https://data.pyg.org/whl/torch-2.4.0%2Bcu121/pyg_lib-0.4.0%2Bpt24cu121-cp310-cp310-linux_x86_64.whl (2.5 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.5/2.5 MB\u001B[0m \u001B[31m17.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting torch_scatter\n",
      "  Downloading https://data.pyg.org/whl/torch-2.4.0%2Bcu121/torch_scatter-2.1.2%2Bpt24cu121-cp310-cp310-linux_x86_64.whl (10.9 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m10.9/10.9 MB\u001B[0m \u001B[31m36.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting torch_sparse\n",
      "  Downloading https://data.pyg.org/whl/torch-2.4.0%2Bcu121/torch_sparse-0.6.18%2Bpt24cu121-cp310-cp310-linux_x86_64.whl (5.1 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m5.1/5.1 MB\u001B[0m \u001B[31m54.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting torch_cluster\n",
      "  Downloading https://data.pyg.org/whl/torch-2.4.0%2Bcu121/torch_cluster-1.6.3%2Bpt24cu121-cp310-cp310-linux_x86_64.whl (3.4 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.4/3.4 MB\u001B[0m \u001B[31m31.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting torch_spline_conv\n",
      "  Downloading https://data.pyg.org/whl/torch-2.4.0%2Bcu121/torch_spline_conv-1.2.2%2Bpt24cu121-cp310-cp310-linux_x86_64.whl (986 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m986.2/986.2 kB\u001B[0m \u001B[31m42.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_sparse) (1.13.1)\n",
      "Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from scipy->torch_sparse) (1.26.4)\n",
      "Installing collected packages: torch_spline_conv, torch_scatter, pyg_lib, torch_sparse, torch_cluster\n",
      "Successfully installed pyg_lib-0.4.0+pt24cu121 torch_cluster-1.6.3+pt24cu121 torch_scatter-2.1.2+pt24cu121 torch_sparse-0.6.18+pt24cu121 torch_spline_conv-1.2.2+pt24cu121\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install rdkit==2022.3.5"
   ],
   "metadata": {
    "id": "mrO7asE88-My",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "2edd53d1-b732-4208-9c5d-77ad56f6b434"
   },
   "id": "mrO7asE88-My",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting rdkit==2022.3.5\n",
      "  Downloading rdkit-2022.3.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rdkit==2022.3.5) (1.26.4)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit==2022.3.5) (11.1.0)\n",
      "Downloading rdkit-2022.3.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.0 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m37.0/37.0 MB\u001B[0m \u001B[31m9.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hInstalling collected packages: rdkit\n",
      "Successfully installed rdkit-2022.3.5\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install torchmetrics"
   ],
   "metadata": {
    "id": "mjrdsp9W8fTr",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "4c5dd059-9e7a-4c6a-f91c-841dfa186850"
   },
   "id": "mjrdsp9W8fTr",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting torchmetrics\n",
      "  Downloading torchmetrics-1.6.1-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.26.4)\n",
      "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (24.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.4.0+cu121)\n",
      "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
      "  Downloading lightning_utilities-0.11.9-py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.1.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.12.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (3.16.1)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (1.13.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (2024.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.0.0->torchmetrics) (12.6.85)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.0.0->torchmetrics) (1.3.0)\n",
      "Downloading torchmetrics-1.6.1-py3-none-any.whl (927 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m927.3/927.3 kB\u001B[0m \u001B[31m22.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading lightning_utilities-0.11.9-py3-none-any.whl (28 kB)\n",
      "Installing collected packages: lightning-utilities, torchmetrics\n",
      "Successfully installed lightning-utilities-0.11.9 torchmetrics-1.6.1\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "id": "9bec6577a3d2a155",
   "metadata": {
    "collapsed": false,
    "id": "9bec6577a3d2a155"
   },
   "source": [
    "# Graph Neural Networks (GNNs)\n",
    "## Part I: Message Passing Neural Networks (MPNNs)\n",
    "We are going to implement few MPNNs for molecular property prediciton. It's recommended that you're familiar with the recent lectures on GNNs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10f517285d85363",
   "metadata": {
    "collapsed": false,
    "id": "a10f517285d85363"
   },
   "source": [
    "# Packages for GNNs\n",
    "There two very popular packages for GNNs that uses pytorch as a backend:\n",
    "1. [PyTorch Geometric](https://pytorch-geometric.readthedocs.io/en/latest/install/installation.html).\n",
    "2. [Deep Graph Library](https://www.dgl.ai/pages/start.html) (along with [dgl-lifesci](https://lifesci.dgl.ai/install/index.html).\n",
    "The former is more stable, the latter has a convenient extension [dgl-lifesci](https://lifesci.dgl.ai/generated/dgllife.utils.CanonicalAtomFeaturizer.html) for molecular data and is generally much more user-friendly. For convenience, we are going to use all three packages, so install appropriate versions of them, please (I recommend installing with pip). If you have issues with installing rdkit (required by dgl-lifesci), you can install rdkit using pip (pip install rdkit)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46af56ed",
   "metadata": {
    "id": "46af56ed"
   },
   "source": [
    "## Installation commands\n",
    "The following commands should work for the `ml` conda env from the `01_zasady_wstep.ipynb`.\n",
    "\n",
    "```\n",
    "conda install -c dglteam/label/cu117 dgl\n",
    "conda install -c conda-forge dgllife\n",
    "conda install pyg -c pyg\n",
    "\n",
    "conda install libboost=1.73.0 boost=1.73.0 boost-cpp=1.73.0\n",
    "pip install rdkit==2022.3.5\n",
    "\n",
    "conda install -c conda-forge torchmetrics\n",
    "conda install -c conda-forge wandb\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61eff200e2fa43b4",
   "metadata": {
    "collapsed": false,
    "id": "61eff200e2fa43b4"
   },
   "source": [
    "# Molecular graphs\n",
    "(Copied from [mldd23 repository](https://github.com/gmum/mldd23/blob/main/labs/L3-graph-neural-networks/laboratory.ipynb))\n",
    "In mathematics, a graph is an object that consists of a set of vertices (nodes) connected with edges, i.e. $\\mathcal{G} = (V, E)$, where $V = \\{ v_i: i \\in \\{1, 2, \\dots, N \\} \\}$ and $E \\subseteq \\{ (v_i, v_j):\\, v_i,v_j \\in V \\}$.\n",
    "\n",
    "Molecular graphs are a special class of graphs, where besides nodes (denoting atoms) and edges (denoting chemical bonds), we have an additional information about atom types and sometimes also bond types. We can assume that we have an additional set of node/atom features encoded as a matrix $X$, where $X_{ij}$ is the $j$-th feature of the $i$-th atom. As atomic features, we can have one-hot encoded atom symbols (a vector containing zeros on all positions besides the position that corresponds to the atom symbol), the number of implicit hydrogens bonded with this atom, or the number of heavy neighbors (atoms other than hydrogens bonded to the given atom).\n",
    "\n",
    "Egdes/bonds can be encoded in two different ways. One method is to use an adjacency matrix $A$, where $A_{ij}=1$ if nodes/atoms $v_i$ nad $v_j$ are connected ($A_{ij}=0$ otherwise). In the case of sparse matrices, a more useful encoding is a list of pairs of connected atoms (a list of index pairs). This latter enocding is used by the PyTorch-Geometric library.\n",
    "\n",
    "In practice, a molecular graph can be described by two matrices: $X \\in \\mathbb{R}^{N \\times F}$ and $E \\in \\{0, 1,\\dots,N-1\\}^{2 \\times N}$, where $N$ is the number of atoms, and $F$ is the number of atomic features.\n",
    "<img src=\"resources/mol_graph.png\" height=\"500\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7533978cf98913d",
   "metadata": {
    "collapsed": false,
    "id": "7533978cf98913d"
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7eeba76a4a89736",
   "metadata": {
    "collapsed": false,
    "id": "f7eeba76a4a89736"
   },
   "source": [
    "We are going to use FreeSolv dataset that contains 642 hydration free energy values for small molecules. The goal is to predict the [hydration free energy](https://en.wikipedia.org/wiki/Hydration_energy) of a given molecule. It's a very commonly used dataset for benchmarking molecular property prediction models. It's small, so we can minimize our co2 footprint and time spent on training.\n",
    "\n",
    "Molecules in most chemical datasets are represented with SMILES. SMILES is a linearization of the molecular graph, it's pretty convenient and can even be used as an input to text-based models. Fortunately, dgllife provides a fancy FreeSolv dataset wrapper that will 1) transform the SMILES into a molecular graph, and 2) encode the nodes and edges with some sensible chemical features (like atom types, bond type etc.) with node and edge features, so we don't really need to care about it."
   ]
  },
  {
   "cell_type": "code",
   "id": "e6b97de5d9371cf2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 158,
     "referenced_widgets": [
      "fa539dc9c8904981b23a6065a6a3e516",
      "219ba23fcecf4eb3850c374b21286bbb",
      "f779c2a5c96744f19d43c2b3da258a8a",
      "1fed2304ca404bf1a058f5d90a1b6e78",
      "c96c361f3f7844f89850ee3d01b9e3ff",
      "4b2a8864cb7942299ccff61c5c40e27b",
      "6b29a8716ad046538992d6fd95749dcc",
      "16efeab8d2d143f58b67b5c31dfb1056",
      "ef46fb48b1ff493f82d6078465bdd08c",
      "6533df93139e445cb60799aae6303aed",
      "90654d49ba3c4083988f377119c12d74"
     ]
    },
    "id": "e6b97de5d9371cf2",
    "outputId": "eeb86bf8-e988-4610-d93a-ec914ed226ed"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "DGL backend not selected or invalid.  Assuming PyTorch for now.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n",
      "Downloading /root/.dgl/FreeSolv.zip from https://data.dgl.ai/dataset/FreeSolv.zip...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "/root/.dgl/FreeSolv.zip:   0%|          | 0.00/11.3k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fa539dc9c8904981b23a6065a6a3e516"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting file to /root/.dgl/FreeSolv\n",
      "Processing dgl graphs from scratch...\n"
     ]
    }
   ],
   "source": [
    "from dgllife.utils import (CanonicalAtomFeaturizer,\n",
    "                           CanonicalBondFeaturizer,\n",
    "                           SMILESToBigraph)\n",
    "from dgllife.data import FreeSolv\n",
    "import torch\n",
    "import dgl\n",
    "\n",
    "node_featurizer = CanonicalAtomFeaturizer()\n",
    "edge_featurizer = CanonicalBondFeaturizer(self_loop=True)\n",
    "dataset = FreeSolv(\n",
    "    smiles_to_graph=SMILESToBigraph(\n",
    "        node_featurizer=node_featurizer,\n",
    "        edge_featurizer=edge_featurizer,\n",
    "        add_self_loop=True, # well... some of the molecules in the dataset contain no edges, so adding the self-loop (edge from node to itself) makes the future MPNN implementations simpler.\n",
    "    ),\n",
    ")"
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "9bf700b3346f6a31",
   "metadata": {
    "collapsed": false,
    "id": "9bf700b3346f6a31"
   },
   "source": [
    "## Playground"
   ]
  },
  {
   "cell_type": "code",
   "id": "fd08f424238c9580",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fd08f424238c9580",
    "outputId": "49e4766f-afdf-414c-964d-36586b61a4de"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "('CN(C)C(=O)c1ccc(cc1)OC',\n",
       " Graph(num_nodes=13, num_edges=39,\n",
       "       ndata_schemes={'h': Scheme(shape=(74,), dtype=torch.float32)}\n",
       "       edata_schemes={'e': Scheme(shape=(13,), dtype=torch.float32)}),\n",
       " tensor([-11.0100]))"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "smiles, graph, label = dataset[0]\n",
    "smiles, graph, label"
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "id": "b297de83ea20e626",
   "metadata": {
    "collapsed": false,
    "id": "b297de83ea20e626"
   },
   "source": [
    "We see that the dataset item consist of a SMILES string, a graph, and a label. The graph is a [DGLGraph](https://docs.dgl.ai/en/0.8.x/api/python/dgl.DGLGraph.html) object that contains node and edge features. We can access them with the following code:"
   ]
  },
  {
   "cell_type": "code",
   "id": "f6cd6aafddd20202",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f6cd6aafddd20202",
    "outputId": "c43d99d3-3316-49b9-eb78-4779ecfccdd5"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([13, 74])"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "graph.ndata['h'].shape  # node features"
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "972195282cdfb48f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "972195282cdfb48f",
    "outputId": "0e262f46-819e-4ecd-ef27-bc71fba830cd"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([39, 13])"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "graph.edata['e'].shape  # edge features"
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "bf1af8de0703b2d3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bf1af8de0703b2d3",
    "outputId": "cfe9de97-dfab-4517-8a74-047b58866e5a"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[12,  0],\n",
       "        [ 0, 12],\n",
       "        [ 0,  2],\n",
       "        [ 2,  0],\n",
       "        [ 0,  4],\n",
       "        [ 4,  0],\n",
       "        [ 4,  7],\n",
       "        [ 7,  4],\n",
       "        [ 4,  9],\n",
       "        [ 9,  4],\n",
       "        [ 9,  6],\n",
       "        [ 6,  9],\n",
       "        [ 6, 10],\n",
       "        [10,  6],\n",
       "        [10, 11],\n",
       "        [11, 10],\n",
       "        [11,  3],\n",
       "        [ 3, 11],\n",
       "        [ 3,  8],\n",
       "        [ 8,  3],\n",
       "        [11,  5],\n",
       "        [ 5, 11],\n",
       "        [ 5,  1],\n",
       "        [ 1,  5],\n",
       "        [ 8,  9],\n",
       "        [ 9,  8],\n",
       "        [ 0,  0],\n",
       "        [ 1,  1],\n",
       "        [ 2,  2],\n",
       "        [ 3,  3],\n",
       "        [ 4,  4],\n",
       "        [ 5,  5],\n",
       "        [ 6,  6],\n",
       "        [ 7,  7],\n",
       "        [ 8,  8],\n",
       "        [ 9,  9],\n",
       "        [10, 10],\n",
       "        [11, 11],\n",
       "        [12, 12]], dtype=torch.int32)"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "start_nodes, end_nodes = graph.edges()  # edges. Note that edges are directed, so we have two edges for each bond. Moreover, we have self-loops, to easily handle molecules with only one atom.\n",
    "edges = torch.stack([start_nodes, end_nodes], dim=1)\n",
    "edges"
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "id": "611ba9d29599927d",
   "metadata": {
    "collapsed": false,
    "id": "611ba9d29599927d"
   },
   "source": [
    "Importantly, if we want to create a batch of graphs, we can simply treat the graphs as... a single graph with many disconnected components. The reason is that MPNN cannot pass the message between disconnected compontents, so the graphs in a batch won't influence each other. To make a batch from two graphs, we can simply run:"
   ]
  },
  {
   "cell_type": "code",
   "id": "1063ec4d70a6c648",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1063ec4d70a6c648",
    "outputId": "4316c2ad-3376-43a6-a832-a9ec10891d14"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(Graph(num_nodes=13, num_edges=39,\n",
       "       ndata_schemes={'h': Scheme(shape=(74,), dtype=torch.float32)}\n",
       "       edata_schemes={'e': Scheme(shape=(13,), dtype=torch.float32)}),\n",
       " Graph(num_nodes=5, num_edges=13,\n",
       "       ndata_schemes={'h': Scheme(shape=(74,), dtype=torch.float32)}\n",
       "       edata_schemes={'e': Scheme(shape=(13,), dtype=torch.float32)}),\n",
       " Graph(num_nodes=18, num_edges=52,\n",
       "       ndata_schemes={'h': Scheme(shape=(74,), dtype=torch.float32)}\n",
       "       edata_schemes={'e': Scheme(shape=(13,), dtype=torch.float32)}))"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "_, graph_1, _ = dataset[0]\n",
    "_, graph_2, _ = dataset[1]\n",
    "collated_graph = dgl.batch([graph_1, graph_2])\n",
    "graph_1, graph_2, collated_graph"
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "cd9357b97e4c3b1b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cd9357b97e4c3b1b",
    "outputId": "dd7bf08e-fc42-461e-af18-8c6e7ba51ed3"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([13,  5], dtype=torch.int32)"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "collated_graph.batch_num_nodes()"
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "id": "b37a35a6ae91e55d",
   "metadata": {
    "collapsed": false,
    "id": "b37a35a6ae91e55d"
   },
   "source": [
    "In the collated_graph, the ids corresponding to the nodes of graph_2 are shifted by the size of graph_1:"
   ]
  },
  {
   "cell_type": "code",
   "id": "7598293d45c78c0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7598293d45c78c0",
    "outputId": "6d9c4abd-389b-4ca7-c622-aa2b6b3fd43e"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12], dtype=torch.int32),\n",
       " tensor([0, 1, 2, 3, 4], dtype=torch.int32),\n",
       " tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17],\n",
       "        dtype=torch.int32))"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "graph_1.nodes(), graph_2.nodes(), collated_graph.nodes()"
   ],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "id": "e67b6515649fa77d",
   "metadata": {
    "collapsed": false,
    "id": "e67b6515649fa77d"
   },
   "source": [
    "## Split\n",
    "We are going to make our split slightly harder by using [scaffold](https://hub.knime.com/infocom/extensions/jp.co.infocom.cheminfo.jchem.feature/latest/jp.co.infocom.cheminfo.jchem.bemismurckoclustering.BemisMurckoClusteringNodeFactory) (scaffold is the largest cycle in a molecule) splitting that puts molecules with similar scaffolds to the same split."
   ]
  },
  {
   "cell_type": "code",
   "id": "901db3d9cdc5a748",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "901db3d9cdc5a748",
    "outputId": "d6dcba45-9d28-45a6-8e19-544f18f355e2"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Start initializing RDKit molecule instances...\n",
      "Start computing Bemis-Murcko scaffolds.\n"
     ]
    }
   ],
   "source": [
    "from dgllife.utils import ScaffoldSplitter\n",
    "\n",
    "splitter = ScaffoldSplitter()\n",
    "train, valid, test = splitter.train_val_test_split(dataset)"
   ],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "id": "b6a601dc47074ca6",
   "metadata": {
    "collapsed": false,
    "id": "b6a601dc47074ca6"
   },
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6593567ea5467",
   "metadata": {
    "collapsed": false,
    "id": "be6593567ea5467"
   },
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "id": "e75cf00937a3c413",
   "metadata": {
    "id": "e75cf00937a3c413"
   },
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "from tqdm.autonotebook import tqdm\n",
    "from dgl.dataloading import GraphDataLoader\n",
    "from torchmetrics import Metric\n",
    "from dgl.data import Subset\n",
    "from torch import nn\n",
    "from typing import Type\n",
    "from typing import Dict, Any\n",
    "from pathlib import Path\n",
    "from abc import ABC, abstractmethod\n",
    "from checker import expected_mean_readout, expected_gin_layer_output, expected_sage_layer_output, \\\n",
    "    expected_attention_readout, expected_gine_layer_output, expected_sum_readout, expected_simple_mpnn_output\n",
    "\n",
    "\n",
    "class LoggerBase(ABC):\n",
    "    def __init__(self, logdir: str | Path):\n",
    "        self.logdir = Path(logdir)\n",
    "        self.logdir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    @abstractmethod\n",
    "    def log_metrics(self, metrics: Dict[str, Any], prefix: str):\n",
    "        ...\n",
    "\n",
    "    @abstractmethod\n",
    "    def close(self):\n",
    "        ...\n",
    "\n",
    "\n",
    "class DummyLogger(LoggerBase):  # If you don't want to use any logger, you can use this one\n",
    "    def log_metrics(self, metrics: Dict[str, Any], prefix: str):\n",
    "        pass\n",
    "\n",
    "    def close(self):\n",
    "        pass\n",
    "\n",
    "    def restart(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "class MetricList:\n",
    "    def __init__(self, metrics: Dict[str, Metric]):\n",
    "        self.metrics = copy.deepcopy(metrics)\n",
    "\n",
    "    def update(self, preds: torch.Tensor, targets: torch.Tensor) -> None:\n",
    "        for name, metric in self.metrics.items():\n",
    "            metric.update(preds.detach().cpu(), targets.cpu())\n",
    "\n",
    "    def compute(self) -> Dict[str, float]:\n",
    "        metrics = {}\n",
    "        for name, metric_fn in self.metrics.items():\n",
    "            metrics[name] = metric_fn.compute().item()\n",
    "            metric_fn.reset()\n",
    "        return metrics\n",
    "\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(\n",
    "            self,\n",
    "            *,\n",
    "            run_dir: str | Path,\n",
    "            train_dataset: Subset,\n",
    "            valid_dataset: Subset,\n",
    "            train_metrics: Dict[str, Metric],\n",
    "            valid_metrics: Dict[str, Metric],\n",
    "            model: nn.Module,\n",
    "            logger: LoggerBase,\n",
    "            optimizer_kwargs: Dict[str, Any],\n",
    "            optimizer_cls: Type[torch.optim.Optimizer] = torch.optim.Adam,\n",
    "            n_epochs: int,\n",
    "            train_batch_size: int = 32,\n",
    "            valid_batch_size: int = 16,\n",
    "            device: str = \"cuda\",\n",
    "            valid_every_n_epochs: int = 1,\n",
    "            loss_fn=nn.MSELoss()\n",
    "    ):\n",
    "        self.run_dir = Path(run_dir)\n",
    "        self.train_loader = GraphDataLoader(\n",
    "            dataset=train_dataset,\n",
    "            batch_size=train_batch_size,\n",
    "            shuffle=True,\n",
    "        )\n",
    "        self.valid_loader = GraphDataLoader(\n",
    "            dataset=valid_dataset,\n",
    "            batch_size=valid_batch_size,\n",
    "            shuffle=True,\n",
    "        )\n",
    "        self.train_metrics = MetricList(train_metrics)\n",
    "        self.valid_metrics = MetricList(valid_metrics)\n",
    "        self.logger = logger\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer_cls(model.parameters(), **optimizer_kwargs)\n",
    "        self.n_epochs = n_epochs\n",
    "        self.device = device\n",
    "        self.valid_every_n_epochs = valid_every_n_epochs\n",
    "        self.loss_fn = loss_fn\n",
    "        self.model.to(device)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def validate(self, dataloader: GraphDataLoader, prefix: str) -> Dict[str, float]:\n",
    "        previous_mode = self.model.training\n",
    "        self.model.eval()\n",
    "        losses = []\n",
    "        for _, graphs, labels in dataloader:\n",
    "            graphs = graphs.to(self.device)\n",
    "            labels = labels.to(self.device)\n",
    "            preds = self.model(graphs)\n",
    "            loss = self.loss_fn(preds, labels)\n",
    "            losses.append(loss.item())\n",
    "            self.valid_metrics.update(preds, labels)\n",
    "        self.model.train(mode=previous_mode)\n",
    "        metrics = {\"loss\": np.mean(losses)} | self.valid_metrics.compute()\n",
    "        self.logger.log_metrics(metrics=metrics, prefix=prefix)\n",
    "        return metrics\n",
    "\n",
    "    def train(self) -> Dict[str, float]:\n",
    "        self.model.train()\n",
    "        valid_metrics = {}\n",
    "        for epoch in tqdm(range(self.n_epochs), total=self.n_epochs):\n",
    "            for _, graphs, labels in self.train_loader:\n",
    "                self.optimizer.zero_grad()\n",
    "                graphs = graphs.to(self.device)\n",
    "                labels = labels.to(self.device)\n",
    "                preds = self.model(graphs)\n",
    "                loss = self.loss_fn(preds, labels)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                self.train_metrics.update(preds, labels)\n",
    "                train_metrics = {\"loss\": loss.item()} | self.train_metrics.compute()\n",
    "                self.logger.log_metrics(metrics=train_metrics, prefix=\"train\")\n",
    "\n",
    "                if epoch % self.valid_every_n_epochs == 0 or epoch == self.n_epochs - 1:\n",
    "                    valid_metrics = self.validate(self.valid_loader, prefix=\"valid\")\n",
    "\n",
    "        return valid_metrics\n",
    "\n",
    "    def test(self, dataset: Subset) -> Dict[str, float]:\n",
    "        dataloader = GraphDataLoader(\n",
    "            dataset=dataset,\n",
    "            batch_size=16,\n",
    "            shuffle=False,\n",
    "        )\n",
    "        return self.validate(dataloader, prefix=\"test\")\n",
    "\n",
    "    def close(self):  # close the logger, not really required for wandb\n",
    "        self.logger.close()"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "id": "7d54c9a1e68cd221",
   "metadata": {
    "collapsed": false,
    "id": "7d54c9a1e68cd221"
   },
   "source": [
    "# Graph Neural Networks (GNNs)\n",
    "The high-level Graph Neural Network architecture we are going to use looks roughly like this:\n",
    "\n",
    "<img src=\"resources/gnn.png\" width=\"1200\" />\n",
    "\n",
    "- The Featurizer takes a molecule and transforms it to a graph with node and edge features (it happens at the level of dataset, so we don't really need to worry about that).\n",
    "- In our case, we will linearly embed the node and edge features to the hidden size before applying first MPNN layer which is not captured in the diagram.\n",
    "- The MPNN layer takes node (and possibly edge embeddings) and the graph structure and returns updated node embeddings. It happens in a loop.\n",
    "- Then the node embeddings are aggregated by the Readout layer to obtain a graph embeddings.\n",
    "- Finally, the graph embeddings are passed to the MLP to obtain the final prediction."
   ]
  },
  {
   "cell_type": "code",
   "id": "e6e7df76cc963d8b",
   "metadata": {
    "id": "e6e7df76cc963d8b"
   },
   "source": [
    "class MPNNLayerBase(ABC, nn.Module):\n",
    "    def _init(self, hidden_size: int):\n",
    "        \"\"\"\n",
    "        Attributes:\n",
    "            hidden_size: the size of node (and edges) embeddings\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "    @abstractmethod\n",
    "    def forward(self,\n",
    "                node_embeddings: torch.Tensor,\n",
    "                edge_embeddings: torch.Tensor,\n",
    "                graph: dgl.DGLGraph) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            node_embeddings: node embeddings in a sparse format, i.e. [total_num_nodes, hidden_size]\n",
    "            edge_embeddings: edge embeddings in a sparse format, i.e. [total_num_edges, hidden_size]\n",
    "            graph: a DGLGraph that contains the graph structure\n",
    "        Returns:\n",
    "            node_embeddings: updated node embeddings in a sparse format, i.e. [total_num_nodes, hidden_size]\n",
    "        \"\"\"\n",
    "        ...\n",
    "\n",
    "\n",
    "class ReadoutBase(nn.Module):\n",
    "    def __init__(self, hidden_size: int):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "    @abstractmethod\n",
    "    def forward(self,\n",
    "                node_embeddings: torch.Tensor,\n",
    "                graph: dgl.DGLGraph) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Attributes:\n",
    "            node_embeddings: node embeddings in a sparse format, i.e. [total_num_nodes, hidden_size]\n",
    "            graph: a DGLGraph that contains the graph structure\n",
    "        Returns:\n",
    "            graph_embeddings: graph embeddings of shape.[batch_size, hidden_size]\n",
    "        \"\"\"\n",
    "        ...\n",
    "\n",
    "\n",
    "class GNN(nn.Module):\n",
    "    def __init__(self,\n",
    "                 node_features_size: int,\n",
    "                 edge_features_size: int,\n",
    "                 hidden_size: int,\n",
    "                 output_size: int,\n",
    "                 mpnn_layer_cls: Type[MPNNLayerBase],\n",
    "                 mpnn_layer_kwargs: Dict[str, Any],\n",
    "                 mpnn_n_layers: int,\n",
    "                 readout_cls: Type[ReadoutBase],\n",
    "                 dropout: float = 0.1,):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            node_features_size: the size of node features\n",
    "            edge_features_size: the size of edge features\n",
    "            hidden_size: the size of node (and edge) embeddings\n",
    "            output_size: the size of the final prediction\n",
    "            mpnn_layer_cls: the class of MPNN layer\n",
    "            mpnn_layer_kwargs: the kwargs for the MPNN layer\n",
    "            mpnn_n_layers: the number of MPNN layers\n",
    "            readout_cls: the class of Readout layer\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.linear_node = nn.Linear(node_features_size, hidden_size)\n",
    "        self.linear_edge = nn.Linear(edge_features_size, hidden_size)\n",
    "        self.mpnn_layers = nn.ModuleList([\n",
    "            mpnn_layer_cls(hidden_size=hidden_size, **mpnn_layer_kwargs)\n",
    "            for _ in range(mpnn_n_layers)\n",
    "        ])\n",
    "        self.dropout = dropout\n",
    "        self.readout = readout_cls(hidden_size=hidden_size)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            # nn.BatchNorm1d(num_features=hidden_size),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_size, output_size),\n",
    "        )\n",
    "\n",
    "    def forward(self, graph: dgl.DGLGraph) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            graph: a DGLGraph that contains the graph structure and node/edge features in a sparse format\n",
    "        Returns:\n",
    "            predictions: the final predictions\n",
    "        \"\"\"\n",
    "        node_embeddings, edge_embeddings = graph.ndata['h'], graph.edata['e']\n",
    "        node_embeddings = self.linear_node(node_embeddings)\n",
    "        edge_embeddings = self.linear_edge(\n",
    "            edge_embeddings)  # some of the models does not use edge features, but we won't use if-clauses for convenience.\n",
    "        for layer in self.mpnn_layers:\n",
    "            node_embeddings = layer(node_embeddings=node_embeddings, edge_embeddings=edge_embeddings, graph=graph)\n",
    "        graph_embedding = self.readout(node_embeddings, graph)\n",
    "        predictions = self.mlp(graph_embedding)\n",
    "        return predictions"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "id": "b9ac59d947b4000b",
   "metadata": {
    "collapsed": false,
    "id": "b9ac59d947b4000b"
   },
   "source": [
    "## Readout\n",
    "Readout operation is used to aggregate node embeddings to obtain a graph embedding. There are many different readout operations, but the most popular are: sum, mean, attention, and max. We are going to implement the first three of them. Summing over nodes' embeddings seems trivial, but they're stored in a sparse format, meaning that all the nodes form all the graphs in a batch are stored in a one tensor of size `[num_nodes_1 + num_nodes_2 + ... + num_nodes_N, hidden_size]':   "
   ]
  },
  {
   "cell_type": "code",
   "id": "473300e58a6023b7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "473300e58a6023b7",
    "outputId": "33cf7b5d-2747-4a16-d697-a95ddf3419fa"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(torch.Size([23, 16]), tensor([13,  5,  5], dtype=torch.int32))"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "batched_graph = dgl.batch([dataset[0][1], dataset[1][1], dataset[2][1]])\n",
    "linear = nn.Linear(node_featurizer.feat_size(), 16)\n",
    "node_embeddings = linear(batched_graph.ndata['h'])\n",
    "node_embeddings.shape, batched_graph.batch_num_nodes()"
   ],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "id": "fce302b7c444ae16",
   "metadata": {
    "collapsed": false,
    "id": "fce302b7c444ae16"
   },
   "source": [
    "For simplicity, we will convert the sparse node embeddings to a dense format with padding. Then the shape of the node embeddings will be `[batch_size, max_num_nodes, hidden_size]`. We can use the `to_dense_batch` function from `torch_geometric` for that:"
   ]
  },
  {
   "cell_type": "code",
   "id": "a3fd81a5384d2ad0",
   "metadata": {
    "id": "a3fd81a5384d2ad0"
   },
   "source": [
    "from typing import Tuple\n",
    "from torch_geometric.utils import to_dense_batch\n",
    "\n",
    "\n",
    "def to_dense_embeddings(node_embeddings: torch.Tensor,\n",
    "                        graph: dgl.DGLGraph,\n",
    "                        fill_value: float = 0.0) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Converts sparse node embeddings to dense node embeddings with padding.\n",
    "    Arguments:\n",
    "        node_embeddings: node embeddings in a sparse format, i.e. [total_num_nodes, hidden_size]\n",
    "        graph: a batch of graphs\n",
    "        fill_value: a value to fill the padding with\n",
    "    Returns:\n",
    "        node_embeddings: node embeddings in a dense format, i.e. [batch_size, max_num_nodes, hidden_size]\n",
    "        mask: a mask indicating which nodes are real and which are padding, i.e. [batch_size, max_num_nodes]\n",
    "    \"\"\"\n",
    "    num_nodes = graph.batch_num_nodes() # e.g. [2, 3, 3]\n",
    "    indices = torch.arange(len(num_nodes), device=num_nodes.device)\n",
    "    batch = torch.repeat_interleave(indices, num_nodes).long() # e.g. [0, 0, 1, 1, 1, 2, 2, 2]\n",
    "    return to_dense_batch(node_embeddings, batch,\n",
    "                          fill_value=fill_value)  # that's the only reason we have torch_geometric in the requirements\n",
    "\n",
    "\n",
    "def to_sparse_embeddings(node_embeddings: torch.Tensor, mask: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Converts dense node embeddings to sparse node embeddings.\n",
    "    Arguments:\n",
    "        node_embeddings: node embeddings in a dense format, i.e. [batch_size, max_num_nodes, hidden_size]\n",
    "        mask: a mask indicating which nodes are real and which are padding, i.e. [batch_size, max_num_nodes]\n",
    "    Returns:\n",
    "        node_embeddings: node embeddings in a sparse format, i.e. [total_num_nodes, hidden_size]\n",
    "    \"\"\"\n",
    "    return node_embeddings[mask]"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "id": "4190f0ff3fa0ae1f",
   "metadata": {
    "collapsed": false,
    "id": "4190f0ff3fa0ae1f"
   },
   "source": [
    "Now, we can simply convert the node embeddings to a dense format and sum them $x = \\sum_i^n x_i$:"
   ]
  },
  {
   "cell_type": "code",
   "id": "841a8932a12397f3",
   "metadata": {
    "id": "841a8932a12397f3"
   },
   "source": [
    "class SumReadout(ReadoutBase):\n",
    "    def forward(self,\n",
    "                node_embeddings: torch.Tensor,\n",
    "                graph: dgl.DGLGraph) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Attributes:\n",
    "            node_embeddings: node embeddings in a sparse format, i.e. [total_num_nodes, hidden_size]\n",
    "            graph: a DGLGraph that contains the graph structure\n",
    "        Returns:\n",
    "            graph_embeddings: graph embeddings of shape.[batch_size, hidden_size]\n",
    "        \"\"\"\n",
    "        # We can also use dgl.sum_nodes function, but let assume it's forbidden in that notebook ;)\n",
    "        node_embeddings, _ = to_dense_embeddings(node_embeddings, graph)\n",
    "        return node_embeddings.sum(dim=1)"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "id": "447a28b93e6e8e89",
   "metadata": {
    "id": "447a28b93e6e8e89"
   },
   "source": [
    "def test_readout(readout_cls: Type[ReadoutBase], expected_output: torch.Tensor):\n",
    "    torch.manual_seed(0)\n",
    "    graph = dgl.batch([dataset[0][1], dataset[1][1], dataset[2][1]])\n",
    "    linear = nn.Linear(node_featurizer.feat_size(), 16)\n",
    "    node_embeddings = linear(graph.ndata['h'])\n",
    "    readout = readout_cls(hidden_size=16)\n",
    "    result = readout(node_embeddings, graph)\n",
    "    assert torch.allclose(result, expected_output, atol=1e-3)"
   ],
   "outputs": [],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "id": "b5dd5e1b3bbde2cc",
   "metadata": {
    "id": "b5dd5e1b3bbde2cc"
   },
   "source": [
    "test_readout(SumReadout, expected_sum_readout)"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "id": "579fd18386daaed",
   "metadata": {
    "collapsed": false,
    "id": "579fd18386daaed"
   },
   "source": [
    "### Task 1. Implement mean readout (1 point).\n",
    "Implement the mean readout given by formula $x = \\frac{1}{n}\\sum_i^n x_i$:"
   ]
  },
  {
   "cell_type": "code",
   "id": "13bd85d993f87d63",
   "metadata": {
    "id": "13bd85d993f87d63"
   },
   "source": [
    "class MeanReadout(ReadoutBase):\n",
    "    def forward(self,\n",
    "                node_embeddings: torch.Tensor,\n",
    "                graph: dgl.DGLGraph) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Attributes:\n",
    "            node_embeddings: node embeddings in a sparse format, i.e. [total_num_nodes, hidden_size]\n",
    "            graph: a DGLGraph that contains the graph structure\n",
    "        Returns:\n",
    "            graph_embeddings: graph embeddings of shape.[batch_size, hidden_size]\n",
    "        \"\"\"\n",
    "        # Don't use any dlg functions here\n",
    "        batch_indices = graph.batch_num_nodes()\n",
    "        start_idx = 0\n",
    "        graph_embeddings = []\n",
    "\n",
    "        for num_nodes in batch_indices:\n",
    "            graph_node_embeddings = node_embeddings[start_idx:start_idx + num_nodes]\n",
    "\n",
    "            graph_mean = graph_node_embeddings.mean(dim=0)\n",
    "            graph_embeddings.append(graph_mean)\n",
    "\n",
    "            start_idx += num_nodes\n",
    "\n",
    "        return torch.stack(graph_embeddings)\n",
    "\n",
    "test_readout(MeanReadout, expected_mean_readout)"
   ],
   "outputs": [],
   "execution_count": 25
  },
  {
   "cell_type": "markdown",
   "id": "db68abdbc2736d7a",
   "metadata": {
    "collapsed": false,
    "id": "db68abdbc2736d7a"
   },
   "source": [
    "### Task 2. Implement attention readout (2 points).\n",
    "Implement the attention readout given by formula $x = \\sum_i^n \\frac{\\exp(score_i))}{\\sum_j^n \\exp(score_j)}x_i$, where $score_i=score\\_mlp(x_i)$:"
   ]
  },
  {
   "cell_type": "code",
   "id": "6c1f5bcdbc90881",
   "metadata": {
    "id": "6c1f5bcdbc90881"
   },
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class AttentionReadout(ReadoutBase):\n",
    "    def __init__(self, hidden_size: int):\n",
    "        super().__init__(hidden_size)\n",
    "        self.score_mlp = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(hidden_size, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self,\n",
    "                node_embeddings: torch.Tensor,\n",
    "                graph: dgl.DGLGraph) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Attributes:\n",
    "            node_embeddings: node embeddings in a sparse format, i.e. [total_num_nodes, hidden_size]\n",
    "            graph: a DGLGraph that contains the graph structure\n",
    "        Returns:\n",
    "            graph_embeddings: graph embeddings of shape.[batch_size, hidden_size]\n",
    "        \"\"\"\n",
    "        batch_indices = graph.batch_num_nodes()\n",
    "        start_idx = 0\n",
    "        graph_embeddings = []\n",
    "\n",
    "        for num_nodes in batch_indices:\n",
    "            graph_node_embeddings = node_embeddings[start_idx:start_idx + num_nodes]\n",
    "\n",
    "            scores = self.score_mlp(graph_node_embeddings)\n",
    "            scores = scores.squeeze(dim=-1)\n",
    "\n",
    "            # Normalize scores using softmax\n",
    "            attention_weights = F.softmax(scores, dim=0)\n",
    "\n",
    "            graph_embedding = torch.sum(attention_weights.unsqueeze(dim=-1) * graph_node_embeddings, dim=0)\n",
    "            graph_embeddings.append(graph_embedding)\n",
    "\n",
    "            start_idx += num_nodes\n",
    "\n",
    "        return torch.stack(graph_embeddings)\n",
    "\n",
    "test_readout(AttentionReadout, expected_attention_readout)"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "id": "ac465a3b9279474b",
   "metadata": {
    "collapsed": false,
    "id": "ac465a3b9279474b"
   },
   "source": [
    "## Message Passing Neural Networks (MPNNs)\n",
    "Message Passing is given by formula:\n",
    "$$\n",
    "x'_i=\\rho(x_i, \\square_{j\\in N(i)} \\psi(x_j, x_i, e_{ji})),\n",
    "$$\n",
    "where $\\psi$ is learnable message function, $\\rho$ is learnable update, and $\\square$ is aggregation function. $N(i)$ denotes the set of neighbors of node $i$. Note that in our dataset we added self-loops to every node, so $N(i)$ also contains $i$, but we don't bother with that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307c236e3cb84e76",
   "metadata": {
    "collapsed": false,
    "id": "307c236e3cb84e76"
   },
   "source": [
    "### Simple MPNN\n",
    "For instance, we can define a very simple MPNN layer by the following formula:\n",
    "$$\n",
    "x'_i=W_1x_i + W_2\\sum_{j\\in N(i)} W_3x_j,\n",
    "$$\n",
    "where W_i are linear layers with implicit bias term (we will make the bias implicit in every formula in that notebook). Let us implement this simple MPNN:"
   ]
  },
  {
   "cell_type": "code",
   "id": "f11f284c299831ed",
   "metadata": {
    "id": "f11f284c299831ed"
   },
   "source": [
    "class SimpleMPNNLayer(MPNNLayerBase):\n",
    "    def __init__(self, hidden_size: int, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.linear_1 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.linear_2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.linear_3 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.batch_norm = nn.BatchNorm1d(hidden_size)\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self,\n",
    "                node_embeddings: torch.Tensor,\n",
    "                edge_embeddings: torch.Tensor,\n",
    "                graph: dgl.DGLGraph) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            node_embeddings: node embeddings in a sparse format, i.e. [total_num_nodes, hidden_size]\n",
    "            edge_embeddings: edge embeddings in a sparse format, i.e. [total_num_edges, hidden_size]\n",
    "            graph: a DGLGraph that contains the graph structure\n",
    "        Returns:\n",
    "            node_embeddings: updated node embeddings in a sparse format, i.e. [total_num_nodes, hidden_size]\n",
    "        \"\"\"\n",
    "\n",
    "        start_nodes, end_nodes = graph.edges(order='srcdst')\n",
    "        messages = self.linear_3(node_embeddings[end_nodes])\n",
    "        message_dense, _ = to_dense_batch(messages, start_nodes.long(), fill_value=0.0)\n",
    "        aggregated_message = message_dense.sum(dim=1)\n",
    "        aggregated_message = self.linear_2(aggregated_message)\n",
    "        node_embeddings = self.linear_1(node_embeddings) + aggregated_message\n",
    "\n",
    "        # node_embeddings = self.batch_norm(node_embeddings)\n",
    "        # node_embeddings = F.dropout(node_embeddings, p=self.dropout, training=self.training)\n",
    "\n",
    "        return node_embeddings"
   ],
   "outputs": [],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "id": "8767bffa62008f67",
   "metadata": {
    "id": "8767bffa62008f67"
   },
   "source": [
    "def test_mpnn_layer(mpnn_layer_cls: Type[MPNNLayerBase], expected_output: torch.Tensor):\n",
    "    torch.manual_seed(0)\n",
    "    graph = dgl.batch([dataset[0][1], dataset[1][1]])\n",
    "    linear_nodes = nn.Linear(node_featurizer.feat_size(), 4)\n",
    "    linear_edges = nn.Linear(edge_featurizer.feat_size(), 4)\n",
    "    node_embeddings = linear_nodes(graph.ndata['h'])\n",
    "    edge_embeddings = linear_edges(graph.edata['e'])\n",
    "    layer = mpnn_layer_cls(hidden_size=4)\n",
    "    result = layer(node_embeddings, edge_embeddings, graph)\n",
    "    assert torch.allclose(result, expected_output, atol=1e-3)"
   ],
   "outputs": [],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "id": "461980b684728501",
   "metadata": {
    "id": "461980b684728501"
   },
   "source": [
    "test_mpnn_layer(SimpleMPNNLayer, expected_simple_mpnn_output)"
   ],
   "outputs": [],
   "execution_count": 29
  },
  {
   "cell_type": "markdown",
   "id": "d0dbbc2f2efa8ca2",
   "metadata": {
    "collapsed": false,
    "id": "d0dbbc2f2efa8ca2"
   },
   "source": [
    "### Task 3. Implement GraphSAGE layer (2 points).\n",
    "Implement a GraphSAGE given by the following formula:\n",
    "$$\n",
    "x'_i=W_1x_i + W_2\\frac{1}{deg(i)}\\sum_{j\\in N(i)} x_j,\n",
    "$$\n",
    "where $deg(i) = #N(i)$ is the number of neighbors of node $i$."
   ]
  },
  {
   "cell_type": "code",
   "id": "82528a8dacf24cd3",
   "metadata": {
    "id": "82528a8dacf24cd3"
   },
   "source": [
    "class SAGELayer(MPNNLayerBase):\n",
    "    def __init__(self, hidden_size: int):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.linear_1 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.linear_2 = nn.Linear(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self,\n",
    "                node_embeddings: torch.Tensor,\n",
    "                edge_embeddings: torch.Tensor,\n",
    "                graph: dgl.DGLGraph) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            node_embeddings: node embeddings in a sparse format, i.e. [total_num_nodes, hidden_size]\n",
    "            edge_embeddings: edge embeddings in a sparse format, i.e. [total_num_edges, hidden_size]\n",
    "            graph: a DGLGraph that contains the graph structure\n",
    "        Returns:\n",
    "            node_embeddings: updated node embeddings in a sparse format, i.e. [total_num_nodes, hidden_size]\n",
    "        \"\"\"\n",
    "        with graph.local_scope():\n",
    "            graph.ndata['h'] = node_embeddings\n",
    "\n",
    "            graph.update_all(\n",
    "                message_func=dgl.function.copy_u('h', 'm'),\n",
    "                reduce_func=dgl.function.mean('m', 'neigh_h')\n",
    "            )\n",
    "\n",
    "            h_self = graph.ndata['h']\n",
    "            h_neigh = graph.ndata['neigh_h']\n",
    "\n",
    "            h_self_transformed = self.linear_1(h_self)\n",
    "            h_neigh_transformed = self.linear_2(h_neigh)\n",
    "\n",
    "            updated_embeddings = h_self_transformed + h_neigh_transformed\n",
    "\n",
    "            return updated_embeddings\n",
    "\n",
    "test_mpnn_layer(SAGELayer, expected_sage_layer_output)"
   ],
   "outputs": [],
   "execution_count": 30
  },
  {
   "cell_type": "markdown",
   "id": "ea8735b272ecad46",
   "metadata": {
    "collapsed": false,
    "id": "ea8735b272ecad46"
   },
   "source": [
    "### Task 4. Implement GIN layer (2 points).\n",
    "Implement a GIN layer given by the following formula:\n",
    "$$\n",
    "x'_i=mlp((1 + \\epsilon)x_i + \\sum_{j\\in N(i)} x_j).\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "id": "e422bea1856fc29",
   "metadata": {
    "id": "e422bea1856fc29"
   },
   "source": [
    "class GINLayer(MPNNLayerBase):\n",
    "    def __init__(self, hidden_size: int, eps: float = 0.0):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.eps = eps\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "        )\n",
    "\n",
    "    def forward(self,\n",
    "                node_embeddings: torch.Tensor,\n",
    "                edge_embeddings: torch.Tensor,\n",
    "                graph: dgl.DGLGraph) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            node_embeddings: node embeddings in a sparse format, i.e. [total_num_nodes, hidden_size]\n",
    "            edge_embeddings: edge embeddings in a sparse format, i.e. [total_num_edges, hidden_size]\n",
    "            graph: a DGLGraph that contains the graph structure\n",
    "        Returns:\n",
    "            node_embeddings: updated node embeddings in a sparse format, i.e. [total_num_nodes, hidden_size]\n",
    "        \"\"\"\n",
    "        with graph.local_scope():\n",
    "            graph.ndata['h'] = node_embeddings\n",
    "\n",
    "            graph.update_all(\n",
    "                message_func=dgl.function.copy_u('h', 'm'),\n",
    "                reduce_func=dgl.function.sum('m', 'neigh_h')\n",
    "            )\n",
    "\n",
    "            h_self = graph.ndata['h']\n",
    "            h_neigh = graph.ndata['neigh_h']\n",
    "\n",
    "            h_combined = (1 + self.eps) * h_self + h_neigh\n",
    "\n",
    "            updated_embeddings = self.mlp(h_combined)\n",
    "\n",
    "            return updated_embeddings\n",
    "\n",
    "test_mpnn_layer(GINLayer, expected_gin_layer_output)"
   ],
   "outputs": [],
   "execution_count": 31
  },
  {
   "cell_type": "markdown",
   "id": "9fe4ec2134b539da",
   "metadata": {
    "collapsed": false,
    "id": "9fe4ec2134b539da"
   },
   "source": [
    "### Task 5. Implement GINE layer (2 points).\n",
    "Implement a GINE layer given by the following formula:\n",
    "$$\n",
    "x'_i=mlp((1 + \\epsilon)x_i + \\sum_{j\\in N(i)} ReLU(x_j + e_{ji})).\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "id": "635e6bcb4e40fdd2",
   "metadata": {
    "id": "635e6bcb4e40fdd2"
   },
   "source": [
    "class GINELayer(MPNNLayerBase):\n",
    "    def __init__(self, hidden_size: int, eps: float = 0.0):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.eps = eps\n",
    "        self.relu = nn.ReLU()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "        )\n",
    "\n",
    "    def forward(self,\n",
    "                node_embeddings: torch.Tensor,\n",
    "                edge_embeddings: torch.Tensor,\n",
    "                graph: dgl.DGLGraph) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            node_embeddings: node embeddings in a sparse format, i.e. [total_num_nodes, hidden_size]\n",
    "            edge_embeddings: edge embeddings in a sparse format, i.e. [total_num_edges, hidden_size]\n",
    "            graph: a DGLGraph that contains the graph structure\n",
    "        Returns:\n",
    "            node_embeddings: updated node embeddings in a sparse format, i.e. [total_num_nodes, hidden_size]\n",
    "        \"\"\"\n",
    "        start_nodes, end_nodes, edge_ids = graph.edges(order='srcdst', form='all')\n",
    "        edge_messages = self.relu(node_embeddings[start_nodes] + edge_embeddings[edge_ids])\n",
    "        neighbor_sum = torch.zeros_like(node_embeddings)\n",
    "        neighbor_sum.index_add_(0, end_nodes, edge_messages)\n",
    "\n",
    "        combined = (1 + self.eps) * node_embeddings + neighbor_sum\n",
    "        updated_embeddings = self.mlp(combined)\n",
    "\n",
    "        return updated_embeddings\n",
    "\n",
    "test_mpnn_layer(GINELayer, expected_gine_layer_output)"
   ],
   "outputs": [],
   "execution_count": 32
  },
  {
   "cell_type": "markdown",
   "id": "6b220afd7f1d78b8",
   "metadata": {
    "collapsed": false,
    "id": "6b220afd7f1d78b8"
   },
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f465e5d378487e7",
   "metadata": {
    "collapsed": false,
    "id": "2f465e5d378487e7"
   },
   "source": [
    "## Logger\n",
    "We are going to use [wandb](https://wandb.ai/site) for logging. It's a very convenient tool for logging and visualizing the training process. It's free for academic use, so you can create an account and use it for your projects. If you don't want to use wandb, you can use any other online logger (like [comet.ml](https://www.comet.ml/site/)), but you need to implement the appropriate LoggerBase subclass on your own. To setup and use wandb, you need to do the following:\n",
    "1. [Setup the wandb](https://docs.wandb.ai/quickstart) (or any other online logger).\n",
    "2. Give your supervisor access to your project (ask him/her about the username.\n",
    "3. Use the logger for all your trainings and provide the links to the final runs."
   ]
  },
  {
   "cell_type": "code",
   "id": "1462ef331426d529",
   "metadata": {
    "id": "1462ef331426d529"
   },
   "source": [
    "class WandbLogger(LoggerBase):\n",
    "    def __init__(\n",
    "            self, logdir: str | Path, project_name: str, experiment_name: str, **kwargs: Dict[str, Any]\n",
    "    ):\n",
    "        super().__init__(logdir)\n",
    "        import wandb\n",
    "        self.project_name = project_name\n",
    "        self.experiment_name = experiment_name\n",
    "        self.kwargs = kwargs\n",
    "        self.run = wandb.init(\n",
    "            dir=self.logdir,\n",
    "            project=self.project_name,\n",
    "            name=self.experiment_name,\n",
    "            entity=\"illia-dovhalenko-jagiellonian-university\",\n",
    "            **self.kwargs,\n",
    "        )\n",
    "\n",
    "    def log_metrics(self, metrics: Dict[str, Any], prefix: str):\n",
    "        metrics = {f\"{prefix}/{k}\": v for k, v in metrics.items()}\n",
    "        self.run.log(metrics)\n",
    "\n",
    "    def close(self):\n",
    "        self.run.finish()"
   ],
   "outputs": [],
   "execution_count": 33
  },
  {
   "cell_type": "markdown",
   "id": "1db91eaab1a90175",
   "metadata": {
    "collapsed": false,
    "id": "1db91eaab1a90175"
   },
   "source": [
    "## Task 6. Train GraphSAGE (2 points).\n",
    "1. Tune hyperparameters of a GNN with `SAGELayer` as MPNN layer to obtain at most 2.0 MAE on the validation set. You can modify the GNN/MPNN architecture, so it uses some regularization tricks like dropout or batch norm. Don't change the validation batch size. If your validation MAE is in (2.0, 2.5], you can obtain 1 point.\n",
    "2. Report the obtained MAE on the validation and test set (only the former need to be lower than 2.0 MAE).\n",
    "3. Provide the link to the final run: https://wandb.ai/illia-dovhalenko-jagiellonian-university/mldd23/runs/wnmf5kur?nw=nwuserilliadovhalenko"
   ]
  },
  {
   "cell_type": "code",
   "id": "e3e9e0cf69701d46",
   "metadata": {
    "id": "e3e9e0cf69701d46"
   },
   "source": [
    "### Example code for training. You can modify it for easier grid-searching."
   ],
   "outputs": [],
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "id": "2980b66ad10a9824",
   "metadata": {
    "id": "2980b66ad10a9824"
   },
   "source": [
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def get_time_stamp() -> str:\n",
    "    return datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")"
   ],
   "outputs": [],
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "id": "18cd039ad8f03ca6",
   "metadata": {
    "id": "18cd039ad8f03ca6",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 913,
     "referenced_widgets": [
      "24a698c45a964885b012461b8601eb1b",
      "d65011d6693242b784b374057e9d00a8",
      "af8a5cd37330445d913617d5c5aa4511",
      "611495124cf64b54a8ee7d4573d33aac",
      "5bc2ce06dea341adb81b647a6b8385de",
      "0187ac2b0f6c4c53a1532b499bddb444",
      "6904138e2f934d4da39ed97368c072a2",
      "9823e8f6bc744407b31a5161423de27b",
      "0428e1d614204a3480fc2b1f61c267a1",
      "38d7d55e8e864906af2a8059407cf756",
      "42ccd219454e484ab04b18cb78123bd9"
     ]
    },
    "outputId": "c3afde5a-677b-43d1-bf52-6f6034f2628d"
   },
   "source": [
    "from torchmetrics import MeanAbsoluteError as MAE\n",
    "from torchmetrics import MeanSquaredError as MSE\n",
    "from torchmetrics import PearsonCorrCoef as PCC\n",
    "\n",
    "metrics = {\n",
    "    \"mae\": MAE(),\n",
    "    \"mse\": MSE(),\n",
    "    \"pcc\": PCC(),\n",
    "}\n",
    "\n",
    "model = GNN(\n",
    "    node_features_size=node_featurizer.feat_size(),\n",
    "    edge_features_size=edge_featurizer.feat_size(),\n",
    "    hidden_size=512,\n",
    "    output_size=1,\n",
    "    mpnn_layer_cls=SAGELayer,\n",
    "    mpnn_n_layers=4,\n",
    "    readout_cls=MeanReadout,\n",
    "    dropout=0.3,\n",
    "    mpnn_layer_kwargs={}\n",
    "\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    run_dir=\"experiments\",\n",
    "    train_dataset=train,\n",
    "    valid_dataset=valid,\n",
    "    train_metrics=metrics,\n",
    "    valid_metrics=metrics,\n",
    "    train_batch_size=32,\n",
    "    model=model,\n",
    "    optimizer_kwargs={\"lr\": 1e-4},\n",
    "    n_epochs=180,\n",
    "    device=\"cpu\",\n",
    "    valid_every_n_epochs=1,\n",
    "    logger=WandbLogger(\n",
    "        logdir=\"runs/mpnn\",\n",
    "        project_name=\"mldd23\",\n",
    "        experiment_name=f\"sage_{get_time_stamp()}\",)\n",
    ")\n",
    "\n",
    "valid_metrics = trainer.train()\n",
    "test_metrics = trainer.test(test)\n",
    "trainer.close()\n",
    "print(f\"Validation metrics: {valid_metrics}\")\n",
    "print(f\"Test metrics: {test_metrics}\")"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/180 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "24a698c45a964885b012461b8601eb1b"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchmetrics/utilities/prints.py:43: UserWarning: The variance of predictions or target is close to zero. This can cause instability in Pearson correlationcoefficient, leading to wrong results. Consider re-scaling the input if possible or computing using alarger dtype (currently using torch.float32).\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/mae</td><td>▁</td></tr><tr><td>test/mse</td><td>▁</td></tr><tr><td>test/pcc</td><td>▁</td></tr><tr><td>train/loss</td><td>█▂▂▂▂▂▃▂▂▂▂▂▂▂▂▁▁▂▁▂▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁</td></tr><tr><td>train/mae</td><td>█▇▇▆▆▅▅▄▆▃▆▂▆▄▄▄▃▄▄▄▅▆▃▂▄▃▂▅▂▂▁▁▂▃▂▂▂▁▂▁</td></tr><tr><td>train/mse</td><td>█▅▇▅▄▅▃▁▃▃▃▅▂▂▃▃▃▃▃▃▂▂▂▃▃▂▃▂▂▂▄▂▂▂▂▁▂▂▃▂</td></tr><tr><td>train/pcc</td><td>▁▆█▅▇▅▆▆▇▇▇▆▇▇█▇█▇▇▇▇▇█▇███▇█▇ ██████▇██</td></tr><tr><td>valid/loss</td><td>█▆▆▅▆▅▃▃▄▂▂▃▂▂▃▂▂▂▁▂▁▁▁▁▂▁▁▁▂▁▁▁▁▁▁▁▃▃▃▂</td></tr><tr><td>valid/mae</td><td>█▆▆▅▅▃▅▃▂▃▃▃▃▃▃▃▂▃▃▁▃▂▂▂▂▃▂▂▂▂▁▁▂▁▁▁▁▁▂▂</td></tr><tr><td>valid/mse</td><td>██▆▄▅▄▃▃▃▅▁▂▃▂▂▂▂▃▂▁▁▂▁▂▁▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>valid/pcc</td><td>▁▄▄▇▇▇▇▇████████████████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test/loss</td><td>5.56998</td></tr><tr><td>test/mae</td><td>1.98137</td></tr><tr><td>test/mse</td><td>6.7039</td></tr><tr><td>test/pcc</td><td>0.74334</td></tr><tr><td>train/loss</td><td>0.69376</td></tr><tr><td>train/mae</td><td>0.83292</td></tr><tr><td>train/mse</td><td>0.69376</td></tr><tr><td>train/pcc</td><td>nan</td></tr><tr><td>valid/loss</td><td>7.03538</td></tr><tr><td>valid/mae</td><td>1.98961</td></tr><tr><td>valid/mse</td><td>7.03538</td></tr><tr><td>valid/pcc</td><td>0.91857</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">sage_2025-01-12_19-21-04</strong> at: <a href='https://wandb.ai/illia-dovhalenko-jagiellonian-university/mldd23/runs/s1f4z3qe' target=\"_blank\">https://wandb.ai/illia-dovhalenko-jagiellonian-university/mldd23/runs/s1f4z3qe</a><br> View project at: <a href='https://wandb.ai/illia-dovhalenko-jagiellonian-university/mldd23' target=\"_blank\">https://wandb.ai/illia-dovhalenko-jagiellonian-university/mldd23</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>runs/mpnn/wandb/run-20250112_192245-s1f4z3qe/logs</code>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Validation metrics: {'loss': 7.03538316488266, 'mae': 1.9896126985549927, 'mse': 7.035383224487305, 'pcc': 0.9185743927955627}\n",
      "Test metrics: {'loss': 5.569980645179749, 'mae': 1.9813652038574219, 'mse': 6.703904628753662, 'pcc': 0.7433377504348755}\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "cell_type": "markdown",
   "id": "c0acbbdb6f55d814",
   "metadata": {
    "collapsed": false,
    "id": "c0acbbdb6f55d814"
   },
   "source": [
    "## Task 7. Train GIN (2 points).\n",
    "1. Tune hyperparameters of a GNN with `GINLayer` as MPNN layer to obtain at most 2.0 MAE on the validation set. You can modify the GNN/MPNN architecture, so it uses some regularization tricks like dropout or batch norm. Don't change the validation batch size. If your validation MAE is in (2.0, 2.5], you can obtain 1 point.\n",
    "2. Report the obtained MAE on the validation and test set (only the former need to be lower than 2.0 MAE).\n",
    "3. Provide the link to the final run: https://wandb.ai/illia-dovhalenko-jagiellonian-university/mldd23/runs/cqy0t98m?nw=nwuserilliadovhalenko"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from torchmetrics import MeanAbsoluteError as MAE\n",
    "from torchmetrics import MeanSquaredError as MSE\n",
    "from torchmetrics import PearsonCorrCoef as PCC\n",
    "\n",
    "metrics = {\n",
    "    \"mae\": MAE(),\n",
    "    \"mse\": MSE(),\n",
    "    \"pcc\": PCC(),\n",
    "}\n",
    "\n",
    "model = GNN(\n",
    "    node_features_size=node_featurizer.feat_size(),\n",
    "    edge_features_size=edge_featurizer.feat_size(),\n",
    "    hidden_size=768,\n",
    "    output_size=1,\n",
    "    mpnn_layer_cls=GINLayer,\n",
    "    mpnn_n_layers=4,\n",
    "    readout_cls=MeanReadout,\n",
    "    dropout=0.4,\n",
    "    mpnn_layer_kwargs={}\n",
    "\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    run_dir=\"experiments\",\n",
    "    train_dataset=train,\n",
    "    valid_dataset=valid,\n",
    "    train_metrics=metrics,\n",
    "    valid_metrics=metrics,\n",
    "    train_batch_size=32,\n",
    "    model=model,\n",
    "    optimizer_kwargs={\"lr\": 1e-4},\n",
    "    n_epochs=50,\n",
    "    device=\"cuda\",\n",
    "    valid_every_n_epochs=1,\n",
    "    logger=WandbLogger(\n",
    "        logdir=\"runs/mpnn\",\n",
    "        project_name=\"mldd23\",\n",
    "        experiment_name=f\"gin_{get_time_stamp()}\",)\n",
    ")\n",
    "\n",
    "valid_metrics = trainer.train()\n",
    "test_metrics = trainer.test(test)\n",
    "trainer.close()\n",
    "print(f\"Validation metrics: {valid_metrics}\")\n",
    "print(f\"Test metrics: {test_metrics}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 944,
     "referenced_widgets": [
      "7992794b2c0347cb8ffb9ce4a165fbc8",
      "a7221ddb4ed147398d2363ab73214fcb",
      "0b509153181c4a36aa854f35bfed2716",
      "6855b56458634703a69824be33a3100b",
      "a75568079b3d4699b48c079ea96c0b73",
      "c479a149f2a84aa4b0a348afae4ae734",
      "8f4a07b6c23247bdbc4bb4cf35c54fe7",
      "63e0193398e2476ca0c68b44099f9be8",
      "175cf0b8f963447d870b827ff495d532",
      "54c30413c73143f5a064df66bddbc7c6",
      "abfbde62d4054956a728d3c377539598"
     ]
    },
    "id": "VeYAL5U_D84G",
    "outputId": "742e97ed-d863-4390-9dc7-2fea68d88a68"
   },
   "id": "VeYAL5U_D84G",
   "execution_count": 75,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.19.1"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>runs/mpnn/wandb/run-20250106_145740-cqy0t98m</code>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/illia-dovhalenko-jagiellonian-university/mldd23/runs/cqy0t98m' target=\"_blank\">gin_2025-01-06_14-57-40</a></strong> to <a href='https://wandb.ai/illia-dovhalenko-jagiellonian-university/mldd23' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/illia-dovhalenko-jagiellonian-university/mldd23' target=\"_blank\">https://wandb.ai/illia-dovhalenko-jagiellonian-university/mldd23</a>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/illia-dovhalenko-jagiellonian-university/mldd23/runs/cqy0t98m' target=\"_blank\">https://wandb.ai/illia-dovhalenko-jagiellonian-university/mldd23/runs/cqy0t98m</a>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7992794b2c0347cb8ffb9ce4a165fbc8"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/mae</td><td>▁</td></tr><tr><td>test/mse</td><td>▁</td></tr><tr><td>test/pcc</td><td>▁</td></tr><tr><td>train/loss</td><td>█▆▅▃▅▃▂▃▄▃▃▄▂▂▂▂▂▁█▂▂▂▃▂▁▁▂▃▂▂▂▂▁▂▁▂▃▂▁▂</td></tr><tr><td>train/mae</td><td>▆▆▆▅█▅▂▅▅▅▄▆▄▄▄▅▃▅▁▃▃▃▂▃▃▃▃▂▂▂▃▂▂▂▃▃▂▂▂▂</td></tr><tr><td>train/mse</td><td>█▅▄▃▂▃▂▃▂▃▁▃▃▃▂▂▂▂▂▁▁▂▂▁▂▁▂▂▁▁▁▁▁▁▁▂▂▂▂▁</td></tr><tr><td>train/pcc</td><td>▂▁▆▄▇▇▂▅▆▅▇██▂▇▇▇▇██▇██▇▇█▇▇██ ▇██▇████ </td></tr><tr><td>valid/loss</td><td>▆█▅▇▇▄▄▃▃▃▄▂▅▃▄▅▂▂▂▁▄▃▂▂▂▂▂▂▂▁▁▁▂▁▁▂▂▂▂▁</td></tr><tr><td>valid/mae</td><td>██▇▇▅▅▄▅▅▄▄▆▅▄▅▄▂▂▂▂▃▃▃▂▂▁▃▂▂▁▂▂▁▁▁▂▅▁▂▂</td></tr><tr><td>valid/mse</td><td>█▇▇▇▅▄▄▄▄▃▂▅▅▃▃▂▂▁▂▂▂▂▂▂▂▁▁▂▂▁▁▂▁▁▁▂▃▁▂▁</td></tr><tr><td>valid/pcc</td><td>▁▂▃▃▆▇▇▇▇██▇███▇▇▇▇▇▇██▇▇▇▇▇▇▇██▇█▇▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test/loss</td><td>5.55259</td></tr><tr><td>test/mae</td><td>1.89287</td></tr><tr><td>test/mse</td><td>6.65626</td></tr><tr><td>test/pcc</td><td>0.71073</td></tr><tr><td>train/loss</td><td>0.12761</td></tr><tr><td>train/mae</td><td>0.35722</td></tr><tr><td>train/mse</td><td>0.12761</td></tr><tr><td>train/pcc</td><td>nan</td></tr><tr><td>valid/loss</td><td>9.96553</td></tr><tr><td>valid/mae</td><td>1.86196</td></tr><tr><td>valid/mse</td><td>9.96553</td></tr><tr><td>valid/pcc</td><td>0.86682</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">gin_2025-01-06_14-57-40</strong> at: <a href='https://wandb.ai/illia-dovhalenko-jagiellonian-university/mldd23/runs/cqy0t98m' target=\"_blank\">https://wandb.ai/illia-dovhalenko-jagiellonian-university/mldd23/runs/cqy0t98m</a><br> View project at: <a href='https://wandb.ai/illia-dovhalenko-jagiellonian-university/mldd23' target=\"_blank\">https://wandb.ai/illia-dovhalenko-jagiellonian-university/mldd23</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>runs/mpnn/wandb/run-20250106_145740-cqy0t98m/logs</code>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Validation metrics: {'loss': 9.965532928705215, 'mae': 1.8619614839553833, 'mse': 9.965533256530762, 'pcc': 0.8668225407600403}\n",
      "Test metrics: {'loss': 5.552593576908111, 'mae': 1.8928728103637695, 'mse': 6.656263828277588, 'pcc': 0.7107284069061279}\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100ee2cd44877b2c",
   "metadata": {
    "collapsed": false,
    "id": "100ee2cd44877b2c"
   },
   "source": [
    "## Task 8. Train GINE (2 points).\n",
    "1. Tune hyperparameters of a GNN with `GINELayer` as MPNN layer to obtain at most 2.0 MAE on the validation set. You can modify the GNN/MPNN architecture, so it uses some regularization tricks like dropout or batch norm. Don't change the validation batch size. If your validation MAE is in (2.0, 2.5], you can obtain 1 point.\n",
    "2. Report the obtained MAE on the validation and test set (only the former need to be lower than 2.0 MAE).\n",
    "3. Provide the link to the final run: https://wandb.ai/illia-dovhalenko-jagiellonian-university/mldd23/runs/z2cjdu41?nw=nwuserilliadovhalenko"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from torchmetrics import MeanAbsoluteError as MAE\n",
    "from torchmetrics import MeanSquaredError as MSE\n",
    "from torchmetrics import PearsonCorrCoef as PCC\n",
    "\n",
    "metrics = {\n",
    "    \"mae\": MAE(),\n",
    "    \"mse\": MSE(),\n",
    "    \"pcc\": PCC(),\n",
    "}\n",
    "\n",
    "model = GNN(\n",
    "    node_features_size=node_featurizer.feat_size(),\n",
    "    edge_features_size=edge_featurizer.feat_size(),\n",
    "    hidden_size=256,\n",
    "    output_size=1,\n",
    "    mpnn_layer_cls=GINELayer,\n",
    "    mpnn_n_layers=3,\n",
    "    readout_cls=MeanReadout,\n",
    "    dropout=0.4,\n",
    "    mpnn_layer_kwargs={}\n",
    "\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    run_dir=\"experiments\",\n",
    "    train_dataset=train,\n",
    "    valid_dataset=valid,\n",
    "    train_metrics=metrics,\n",
    "    valid_metrics=metrics,\n",
    "    train_batch_size=32,\n",
    "    model=model,\n",
    "    optimizer_kwargs={\"lr\": 1e-4},\n",
    "    n_epochs=120,\n",
    "    device=\"cpu\",\n",
    "    valid_every_n_epochs=1,\n",
    "    logger=WandbLogger(\n",
    "        logdir=\"runs/mpnn\",\n",
    "        project_name=\"mldd23\",\n",
    "        experiment_name=f\"gine_{get_time_stamp()}\",)\n",
    ")\n",
    "\n",
    "valid_metrics = trainer.train()\n",
    "test_metrics = trainer.test(test)\n",
    "trainer.close()\n",
    "print(f\"Validation metrics: {valid_metrics}\")\n",
    "print(f\"Test metrics: {test_metrics}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 944,
     "referenced_widgets": [
      "e2158f725aa74cd6a30b9dce67123a67",
      "68850fffdbbe47d2a710d13065281183",
      "5580fcd9087146148bb0ed21a6ca10a2",
      "ccbae9f26c7e405987a56b6917272446",
      "bafc47e817fc4180952b731304b4e56a",
      "9224529e3aeb461c97f696778ec59aa0",
      "744f2fd4852a4199b9bc2c0715753446",
      "988e4d9dc8b74299b43495708903b635",
      "7eac521d526b4557ac557f28b3f238a8",
      "b69c7cae43de4090a8e56cdd5388c583",
      "69cdca9e800b4e5993f41bfab02c6db8"
     ]
    },
    "id": "9HtWwxvB-QRx",
    "outputId": "ce6f878c-32b7-4a27-af45-95bc84ab7236"
   },
   "id": "9HtWwxvB-QRx",
   "execution_count": 45,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.19.1"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>runs/mpnn/wandb/run-20250112_195653-z2cjdu41</code>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/illia-dovhalenko-jagiellonian-university/mldd23/runs/z2cjdu41' target=\"_blank\">gine_2025-01-12_19-56-53</a></strong> to <a href='https://wandb.ai/illia-dovhalenko-jagiellonian-university/mldd23' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/illia-dovhalenko-jagiellonian-university/mldd23' target=\"_blank\">https://wandb.ai/illia-dovhalenko-jagiellonian-university/mldd23</a>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/illia-dovhalenko-jagiellonian-university/mldd23/runs/z2cjdu41' target=\"_blank\">https://wandb.ai/illia-dovhalenko-jagiellonian-university/mldd23/runs/z2cjdu41</a>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/120 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e2158f725aa74cd6a30b9dce67123a67"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/mae</td><td>▁</td></tr><tr><td>test/mse</td><td>▁</td></tr><tr><td>test/pcc</td><td>▁</td></tr><tr><td>train/loss</td><td>█▆▃▂▃▃▃▁▂▂▂▂▁▂▁▂▂▂▂▁▁▂▂▂▂▁▂▂▁▁▁▁▁▁▂▁▁▁▁▁</td></tr><tr><td>train/mae</td><td>▇▆█▆▆▅▄▄▃▃▃▂▃▃▄▃▃▂▄▃▃▂▃▃▃▂▂▂▃▃▃▃▄▄▁▂▂▃▂▂</td></tr><tr><td>train/mse</td><td>█▅▅▅▆▅▃▃█▃▃▂▂▂▂▂▂▂▂▂▁▂▁▂▁▂▅▁▂▁▁▁▁▁▂▁▁▁▂▂</td></tr><tr><td>train/pcc</td><td>▁▅▃▂▆▆▇▆▇▇▇█▇▇▇▇██▇█████████████████████</td></tr><tr><td>valid/loss</td><td>██▆▆▅▆▄▃▃▃▃▄▂▃▂▂▂▂▂▂▂▁▂▂▁▂▂▂▁▂▂▂▁▂▁▁▂▂▁▁</td></tr><tr><td>valid/mae</td><td>██▅▅▅▄▄▄▃▄▄▃▃▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▁▁▁▂▁▁</td></tr><tr><td>valid/mse</td><td>▇█▇▇▆▇▅▆▅▅▄▃▃▃▂▂▂▂▁▂▁▂▂▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>valid/pcc</td><td>▁▂▆▇▇▇▇▇▇▇▇█▇▇▇███▇█████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test/loss</td><td>3.74771</td></tr><tr><td>test/mae</td><td>1.53817</td></tr><tr><td>test/mse</td><td>4.52389</td></tr><tr><td>test/pcc</td><td>0.81387</td></tr><tr><td>train/loss</td><td>0.60715</td></tr><tr><td>train/mae</td><td>0.7792</td></tr><tr><td>train/mse</td><td>0.60715</td></tr><tr><td>train/pcc</td><td>nan</td></tr><tr><td>valid/loss</td><td>7.95432</td></tr><tr><td>valid/mae</td><td>1.81346</td></tr><tr><td>valid/mse</td><td>7.95432</td></tr><tr><td>valid/pcc</td><td>0.94579</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">gine_2025-01-12_19-56-53</strong> at: <a href='https://wandb.ai/illia-dovhalenko-jagiellonian-university/mldd23/runs/z2cjdu41' target=\"_blank\">https://wandb.ai/illia-dovhalenko-jagiellonian-university/mldd23/runs/z2cjdu41</a><br> View project at: <a href='https://wandb.ai/illia-dovhalenko-jagiellonian-university/mldd23' target=\"_blank\">https://wandb.ai/illia-dovhalenko-jagiellonian-university/mldd23</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>runs/mpnn/wandb/run-20250112_195653-z2cjdu41/logs</code>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Validation metrics: {'loss': 7.95431661605835, 'mae': 1.8134554624557495, 'mse': 7.95431661605835, 'pcc': 0.9457873106002808}\n",
      "Test metrics: {'loss': 3.7477149248123167, 'mae': 1.5381650924682617, 'mse': 4.523894309997559, 'pcc': 0.8138684034347534}\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802615e3afaddf44",
   "metadata": {
    "collapsed": false,
    "id": "802615e3afaddf44"
   },
   "source": [
    "# Code optimization\n",
    "Some pieces of code were written suboptimally. Your task is to slightly optimize them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c64785b23a2b1d",
   "metadata": {
    "collapsed": false,
    "id": "17c64785b23a2b1d"
   },
   "source": [
    "## Task 9. Optimize SumReadout (1 point).\n",
    "`SumReadout` was written using `to_dense_embeddings` function which does some unecessary memory allocations and computations. Your task is to rewrite the method using code from a bare torch library. Hint: `torch.index_add`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "292cb0197e977862",
   "metadata": {
    "is_executing": true,
    "id": "292cb0197e977862"
   },
   "source": [
    "class OptimizedSumReadout(ReadoutBase):\n",
    "    def forward(self,\n",
    "                node_embeddings: torch.Tensor,\n",
    "                graph: dgl.DGLGraph) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Attributes:\n",
    "            node_embeddings: node embeddings in a sparse format, i.e. [total_num_nodes, hidden_size]\n",
    "            graph: a DGLGraph that contains the graph structure\n",
    "        Returns:\n",
    "            graph_embeddings: graph embeddings of shape.[batch_size, hidden_size]\n",
    "        \"\"\"\n",
    "        batch_indices = graph.batch_num_nodes().cumsum(dim=0).roll(shifts=1, dims=0)\n",
    "        batch_indices[0] = 0\n",
    "        batch_indices = torch.arange(graph.batch_size, device=node_embeddings.device).repeat_interleave(graph.batch_num_nodes())\n",
    "\n",
    "\n",
    "        batch_size = graph.batch_size\n",
    "        hidden_size = node_embeddings.size(1)\n",
    "\n",
    "        graph_embeddings = torch.zeros(batch_size, hidden_size, device=node_embeddings.device)\n",
    "\n",
    "        graph_embeddings.index_add_(0, batch_indices, node_embeddings)\n",
    "\n",
    "        return graph_embeddings\n",
    "\n",
    "test_readout(OptimizedSumReadout, expected_sum_readout)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "d4be6a2ed6011b64",
   "metadata": {
    "collapsed": false,
    "id": "d4be6a2ed6011b64"
   },
   "source": [
    "## Task 10. Optimize MeanReadout (1 point).\n",
    "Your task is to rewrite the method using code from a bare torch library."
   ]
  },
  {
   "cell_type": "code",
   "id": "9baf5944d7ad42c2",
   "metadata": {
    "is_executing": true,
    "id": "9baf5944d7ad42c2"
   },
   "source": [
    "class OptimizedMeanReadout(ReadoutBase):\n",
    "    def forward(self,\n",
    "                node_embeddings: torch.Tensor,\n",
    "                graph: dgl.DGLGraph) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Attributes:\n",
    "            node_embeddings: node embeddings in a sparse format, i.e. [total_num_nodes, hidden_size]\n",
    "            graph: a DGLGraph that contains the graph structure\n",
    "        Returns:\n",
    "            graph_embeddings: graph embeddings of shape.[batch_size, hidden_size]\n",
    "        \"\"\"\n",
    "        batch_indices = torch.arange(graph.batch_size, device=node_embeddings.device).repeat_interleave(graph.batch_num_nodes())\n",
    "\n",
    "        batch_size = graph.batch_size\n",
    "        hidden_size = node_embeddings.size(1)\n",
    "\n",
    "        graph_embeddings = torch.zeros(batch_size, hidden_size, device=node_embeddings.device)\n",
    "        node_counts = torch.zeros(batch_size, device=node_embeddings.device).float()\n",
    "\n",
    "        graph_embeddings.index_add_(0, batch_indices, node_embeddings)\n",
    "        node_counts.index_add_(0, batch_indices, torch.ones_like(batch_indices, device=node_embeddings.device).float())\n",
    "\n",
    "        graph_embeddings /= node_counts.unsqueeze(-1)\n",
    "\n",
    "        return graph_embeddings\n",
    "\n",
    "\n",
    "test_readout(OptimizedMeanReadout, expected_mean_readout)"
   ],
   "outputs": [],
   "execution_count": 47
  },
  {
   "cell_type": "markdown",
   "id": "6b0f8cab6725a285",
   "metadata": {
    "collapsed": false,
    "id": "6b0f8cab6725a285"
   },
   "source": [
    "## Task 11. Optimize SimpleMPNNLayer (1 point).\n",
    "We can make our implementations of `SimpleMPNNLayer` layer (and basically any other MPNN layer) slightly faster by:\n",
    "- reducing the costs of the message embedding (in the case of `SimpleMPNNLayer`, it's application of `self.linear_3`) from $O(m)$ to $O(n)$, where $m$ is the number of edges in the graph and $n$ is the number of nodes.\n",
    "- removing quite expensive `to_dense_batch` call.\n",
    "\n",
    "Your task is to apply the above optimizations."
   ]
  },
  {
   "cell_type": "code",
   "id": "862db51e45f8abf",
   "metadata": {
    "is_executing": true,
    "id": "862db51e45f8abf"
   },
   "source": [
    "class OptimizedSimpleMPNNLayer(MPNNLayerBase):\n",
    "    def __init__(self, hidden_size: int, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.linear_1 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.linear_2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.linear_3 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.batch_norm = nn.BatchNorm1d(hidden_size)\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self,\n",
    "                node_embeddings: torch.Tensor,\n",
    "                edge_embeddings: torch.Tensor,\n",
    "                graph: dgl.DGLGraph) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            node_embeddings: Node embeddings in a sparse format, i.e. [total_num_nodes, hidden_size].\n",
    "            edge_embeddings: Edge embeddings in a sparse format, i.e. [total_num_edges, hidden_size].\n",
    "            graph: A DGLGraph that contains the graph structure.\n",
    "        Returns:\n",
    "            Updated node embeddings in a sparse format, i.e. [total_num_nodes, hidden_size].\n",
    "        \"\"\"\n",
    "        src_nodes, dst_nodes = graph.edges(order='srcdst')\n",
    "\n",
    "        dst_nodes = dst_nodes.long()\n",
    "\n",
    "        src_messages = self.linear_3(node_embeddings[src_nodes])\n",
    "\n",
    "        aggregated_messages = torch.zeros_like(node_embeddings, device=node_embeddings.device)\n",
    "        aggregated_messages.scatter_add_(0, dst_nodes.unsqueeze(1).expand(-1, self.hidden_size), src_messages)\n",
    "\n",
    "        aggregated_messages = self.linear_2(aggregated_messages)\n",
    "\n",
    "        node_embeddings = self.linear_1(node_embeddings) + aggregated_messages\n",
    "\n",
    "        # node_embeddings = self.batch_norm(node_embeddings)\n",
    "\n",
    "        # node_embeddings = F.dropout(node_embeddings, p=self.dropout, training=self.training)\n",
    "\n",
    "        return node_embeddings\n",
    "\n",
    "test_mpnn_layer(OptimizedSimpleMPNNLayer, expected_simple_mpnn_output)"
   ],
   "outputs": [],
   "execution_count": 48
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": []
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "fa539dc9c8904981b23a6065a6a3e516": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_219ba23fcecf4eb3850c374b21286bbb",
       "IPY_MODEL_f779c2a5c96744f19d43c2b3da258a8a",
       "IPY_MODEL_1fed2304ca404bf1a058f5d90a1b6e78"
      ],
      "layout": "IPY_MODEL_c96c361f3f7844f89850ee3d01b9e3ff"
     }
    },
    "219ba23fcecf4eb3850c374b21286bbb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4b2a8864cb7942299ccff61c5c40e27b",
      "placeholder": "​",
      "style": "IPY_MODEL_6b29a8716ad046538992d6fd95749dcc",
      "value": "/root/.dgl/FreeSolv.zip: 100%"
     }
    },
    "f779c2a5c96744f19d43c2b3da258a8a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_16efeab8d2d143f58b67b5c31dfb1056",
      "max": 11306,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ef46fb48b1ff493f82d6078465bdd08c",
      "value": 11306
     }
    },
    "1fed2304ca404bf1a058f5d90a1b6e78": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6533df93139e445cb60799aae6303aed",
      "placeholder": "​",
      "style": "IPY_MODEL_90654d49ba3c4083988f377119c12d74",
      "value": " 11.3k/11.3k [00:00&lt;00:00, 9.93kB/s]"
     }
    },
    "c96c361f3f7844f89850ee3d01b9e3ff": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4b2a8864cb7942299ccff61c5c40e27b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6b29a8716ad046538992d6fd95749dcc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "16efeab8d2d143f58b67b5c31dfb1056": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ef46fb48b1ff493f82d6078465bdd08c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6533df93139e445cb60799aae6303aed": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "90654d49ba3c4083988f377119c12d74": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "24a698c45a964885b012461b8601eb1b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d65011d6693242b784b374057e9d00a8",
       "IPY_MODEL_af8a5cd37330445d913617d5c5aa4511",
       "IPY_MODEL_611495124cf64b54a8ee7d4573d33aac"
      ],
      "layout": "IPY_MODEL_5bc2ce06dea341adb81b647a6b8385de"
     }
    },
    "d65011d6693242b784b374057e9d00a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0187ac2b0f6c4c53a1532b499bddb444",
      "placeholder": "​",
      "style": "IPY_MODEL_6904138e2f934d4da39ed97368c072a2",
      "value": "100%"
     }
    },
    "af8a5cd37330445d913617d5c5aa4511": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9823e8f6bc744407b31a5161423de27b",
      "max": 180,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0428e1d614204a3480fc2b1f61c267a1",
      "value": 180
     }
    },
    "611495124cf64b54a8ee7d4573d33aac": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_38d7d55e8e864906af2a8059407cf756",
      "placeholder": "​",
      "style": "IPY_MODEL_42ccd219454e484ab04b18cb78123bd9",
      "value": " 180/180 [10:38&lt;00:00,  3.57s/it]"
     }
    },
    "5bc2ce06dea341adb81b647a6b8385de": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0187ac2b0f6c4c53a1532b499bddb444": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6904138e2f934d4da39ed97368c072a2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9823e8f6bc744407b31a5161423de27b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0428e1d614204a3480fc2b1f61c267a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "38d7d55e8e864906af2a8059407cf756": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "42ccd219454e484ab04b18cb78123bd9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7992794b2c0347cb8ffb9ce4a165fbc8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a7221ddb4ed147398d2363ab73214fcb",
       "IPY_MODEL_0b509153181c4a36aa854f35bfed2716",
       "IPY_MODEL_6855b56458634703a69824be33a3100b"
      ],
      "layout": "IPY_MODEL_a75568079b3d4699b48c079ea96c0b73"
     }
    },
    "a7221ddb4ed147398d2363ab73214fcb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c479a149f2a84aa4b0a348afae4ae734",
      "placeholder": "​",
      "style": "IPY_MODEL_8f4a07b6c23247bdbc4bb4cf35c54fe7",
      "value": "100%"
     }
    },
    "0b509153181c4a36aa854f35bfed2716": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_63e0193398e2476ca0c68b44099f9be8",
      "max": 50,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_175cf0b8f963447d870b827ff495d532",
      "value": 50
     }
    },
    "6855b56458634703a69824be33a3100b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_54c30413c73143f5a064df66bddbc7c6",
      "placeholder": "​",
      "style": "IPY_MODEL_abfbde62d4054956a728d3c377539598",
      "value": " 50/50 [00:36&lt;00:00,  1.42it/s]"
     }
    },
    "a75568079b3d4699b48c079ea96c0b73": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c479a149f2a84aa4b0a348afae4ae734": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8f4a07b6c23247bdbc4bb4cf35c54fe7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "63e0193398e2476ca0c68b44099f9be8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "175cf0b8f963447d870b827ff495d532": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "54c30413c73143f5a064df66bddbc7c6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "abfbde62d4054956a728d3c377539598": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e2158f725aa74cd6a30b9dce67123a67": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_68850fffdbbe47d2a710d13065281183",
       "IPY_MODEL_5580fcd9087146148bb0ed21a6ca10a2",
       "IPY_MODEL_ccbae9f26c7e405987a56b6917272446"
      ],
      "layout": "IPY_MODEL_bafc47e817fc4180952b731304b4e56a"
     }
    },
    "68850fffdbbe47d2a710d13065281183": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9224529e3aeb461c97f696778ec59aa0",
      "placeholder": "​",
      "style": "IPY_MODEL_744f2fd4852a4199b9bc2c0715753446",
      "value": "100%"
     }
    },
    "5580fcd9087146148bb0ed21a6ca10a2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_988e4d9dc8b74299b43495708903b635",
      "max": 120,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7eac521d526b4557ac557f28b3f238a8",
      "value": 120
     }
    },
    "ccbae9f26c7e405987a56b6917272446": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b69c7cae43de4090a8e56cdd5388c583",
      "placeholder": "​",
      "style": "IPY_MODEL_69cdca9e800b4e5993f41bfab02c6db8",
      "value": " 120/120 [03:08&lt;00:00,  1.49s/it]"
     }
    },
    "bafc47e817fc4180952b731304b4e56a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9224529e3aeb461c97f696778ec59aa0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "744f2fd4852a4199b9bc2c0715753446": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "988e4d9dc8b74299b43495708903b635": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7eac521d526b4557ac557f28b3f238a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b69c7cae43de4090a8e56cdd5388c583": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "69cdca9e800b4e5993f41bfab02c6db8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
